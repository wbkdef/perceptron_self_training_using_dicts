{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%loadpy run_log_linear_with_dropout.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import dataImport\n",
      "import DL\n",
      "import misc\n",
      "import Yarowsky\n",
      "import perceptron_dropout_averaging as ped #DELETE\n",
      "import calc_error\n",
      "import string\n",
      "import operator\n",
      "#from pylab import *\n",
      "import itertools\n",
      "import logLinear as ll\n",
      "\n",
      "\n",
      "reload(Yarowsky)\n",
      "data = 'namedentity'\n",
      "\n",
      "train,test,gold,nLabels,rules = dataImport.getData(data)\n",
      "\n",
      "print \"gold length:\",len(gold)\n",
      "\n",
      "# Label training data based on initial seed rules\n",
      "labels = DL.label(train,rules,nLabels)\n",
      "train123=[]\n",
      "labels123=[]\n",
      "train_unlabelled=[]\n",
      "for features, label in zip(train, labels):\n",
      "\tif label==1 or label==2 or label==3:\n",
      "\t\ttrain123.append(features)\n",
      "\t\tlabels123.append(label)\n",
      "\telse:\n",
      "\t\ttrain_unlabelled.append(features)\n",
      "\n",
      "nLabels=3\n",
      "penalty=1 #1 to root n\n",
      "w = logLinear.optimize(train,labels,nLabels,penalty)\n",
      "labelsLL = logLinear.label(test,w,nLabels)\n",
      "print 'Accuracy with log-linear model based on seed rules: ' + \\\n",
      "\tstr(1-(1/nTest)*sum(labelsLL[d]!=gold[d] for d in range(nTest)))\n",
      "\n",
      "\n",
      "assert(False)\n",
      "\n",
      "def do_semi_supervised_iteration(num_to_add, classifier, labeled_features, labels, unlabelled_features, averaged):\n",
      "\tlabels_and_confidence=classifier.predict_labels_with_confidence(unlabelled_features,averaged)\n",
      "\tn=len(unlabelled_features)\n",
      "\tassert len(labels_and_confidence)==n \n",
      "\t# def check_consistency_of_predictions():\n",
      "\t# \tfor lc,feats in itertools.izip(labels_and_confidence,unlabelled_features):\n",
      "\t# \t\tassert classifier.predict_label_with_confidence(feats)==lc \n",
      "\t# check_consistency_of_predictions()\n",
      "\t# def print_ilc(ilcf):\n",
      "\t# \tfor i,l,c,f in ilcf[:10]:\n",
      "\t# \t\tprint \"i,l,c, pl: \", i,l,c,classifier.predict_label_with_confidence(f,averaged)\n",
      "\t# \tprint \"...\"\n",
      "\t# \tfor i,l,c,f in ilcf[-10:]:\n",
      "\t# \t\tprint \"i,l,c, pl: \", i,l,c,classifier.predict_label_with_confidence(f,averaged)\n",
      "\tilcf=[]\n",
      "\tfor i in xrange(n):\n",
      "\t\tl,c=labels_and_confidence[i]\n",
      "\t\tf=unlabelled_features[i]\n",
      "\t\t# if(classifier.predict_label_with_confidence(f,averaged)!=(l,c)): #DEBUG\n",
      "\t\t# \tprint \"i,l,c,pl,pc: \",i,l,c,classifier.predict_label_with_confidence(f)\n",
      "\n",
      "\t\tilcf.append((i,l,c,f))\n",
      "\t# def check_consistency(ilcf):\n",
      "\t# \tfor i,l,c,f in ilcf:\n",
      "\t# \t\tif (classifier.predict_label_with_confidence(f)!=(l,c)):\n",
      "\t# \t\t\tprint \"i,l,c,pl,pc: \",i,l,c,classifier.predict_label_with_confidence(f)\n",
      "\t# \t\t\tassert False #DEBUG\n",
      "\t# check_consistency(ilcf)#DEBUG\n",
      "\n",
      "\t#print_ilc(ilcf) #DEBUG\n",
      "\tilcf=sorted(ilcf, reverse=True,key=operator.itemgetter(2))\n",
      "\t# check_consistency(ilcf)#DEBUG\n",
      "\n",
      "\t#print_ilc(ilcf) #DEBUG\n",
      "\tcount=0\n",
      "\tfor i,l,c,f in ilcf[0:num_to_add]:\n",
      "\t\tlabels.append(l)\n",
      "\t\tlabeled_features.append(f)\n",
      "\t\tcount+=1\n",
      "\t\tif(classifier.predict_label(f,averaged)!=l):\n",
      "\t\t\tprint \"i,l,c,classifier.predict_label(f),count,f\"\n",
      "\t\t\tprint i,l,c,classifier.predict_label(f),count,f\n",
      "\t\t\tassert(False) #DEBUG\n",
      "\t\t#print \"added: \", l, c, f\n",
      "\tnew_unlabelled = [f for i,l,c,f in ilcf[num_to_add:]]\n",
      "\treturn new_unlabelled\n",
      "\n",
      "def do_semi_supervised_learning(num_iterations,num_to_add_each_iteration, perceptron, labeled_features, labels, unlabelled_features,iterations):\n",
      "\ttest_errors=[]\t\n",
      "\ttest_errors_averaged=[]\n",
      "\tfor i in xrange(num_iterations):\n",
      "\t\tprint \"\\n\"\t\t\n",
      "\t\tprint \"Starting iteration \", i, \"of \", num_iterations,\"runtype = \", run_type,\n",
      "\t\tperceptron.train(labeled_features,labels,iterations/3) #to get close to equilibrium first\n",
      "\t\tperceptron.train(labeled_features,labels,iterations)\n",
      "\t\tdef get_errors(feats,labels,averaged):\n",
      "\t\t\tpredicted_labels=perceptron.predict_labels(feats,averaged)\n",
      "\t\t\ttest_num_errors, test_error=calc_error.error(predicted_labels,labels)\n",
      "\t\t\treturn test_num_errors, test_error\n",
      "\n",
      "\t\ttest_num_errors, test_error = get_errors(test,gold,False)\n",
      "\t\tprint test_num_errors, test_error\n",
      "\t\ttest_errors.append(test_error)\n",
      "\t\ttest_num_errors_averaged, test_error_averaged = get_errors(test,gold,True)\n",
      "\t\ttest_errors_averaged.append(test_error_averaged)\n",
      "        if i%5==1:\n",
      "\t\t    print \"training error: \", get_errors(labeled_features,labels,False)\n",
      "\t\t    print \"training error, averaged perceptron: \", get_errors(labeled_features,labels,True)\n",
      "\t\t    print \"iteration \", i, \" test error: \", test_error,\"num errors:\",test_num_errors\n",
      "\t\t    print \"labelled and unlabelled feature vector lengths: \", len(labeled_features), len(unlabelled_features)\n",
      "        if test_error > 0.65:\n",
      "            print 'error condition met '\n",
      "        if i>2:\n",
      "\t\t\tprint \"i>2\"\n",
      "\t\t\tprint \"variation in last 3 iterations: \",max(test_errors[-3:])-min(test_errors[-3:])\n",
      "\t\t\tif max(test_errors[-3:])-min(test_errors[-3:])<0.0000001:\n",
      "\t\t\t\tprint \"Not Changing\\n\"\n",
      "\t\t\t\tbreak\n",
      "\t\t\tif (sum(test_errors[-3:])/3>min(test_errors)+0.15):\n",
      "\t\t\t\tprint \"relativeerror condition met\\n\"\n",
      "\t\t\t\tbreak\n",
      "\t\t\tif (sum(test_errors[-3:])/3>60):\n",
      "\t\t\t\tprint \"error condition met\\n\"\n",
      "\t\t\t\tbreak\n",
      "\n",
      "\t\tunlabelled_features=do_semi_supervised_iteration(num_to_add_each_iteration,\n",
      "\t\t\tperceptron, labeled_features, labels, unlabelled_features, True)\n",
      "\t\t\n",
      "\treturn test_errors,test_errors_averaged\n",
      "\n",
      "# num_perceptrons_in_enssemble=[1,3,10]\n",
      "# # drop_out_rate=[0,.2,.4]\n",
      "# num_perceptrons_in_enssemble=[1]\n",
      "# #drop_out_rate=[0,.2,.4,.6,.8,.9]\n",
      "# drop_out_rate=[.5]\n",
      "# num_to_add=20000\n",
      "# max_iterations_if_0=3\n",
      "# #num_to_add_each_iteration=[4000,1000,250,0]\n",
      "# num_to_add_each_iteration=[1000]\n",
      "# repetitions=10\n",
      "\n",
      "run_type=\"standard\"\n",
      "\n",
      "def set_runtime_parameters(run_type_in):\n",
      "\tglobal run_type\n",
      "\tprint run_type\n",
      "\trun_type=run_type_in\n",
      "\tglobal drop_out_rate\n",
      "\tglobal num_to_add\n",
      "\tglobal max_iterations_if_0\n",
      "\tglobal num_to_add_each_iteration\n",
      "\tglobal repetitions\n",
      "\tglobal iterations\n",
      "\tglobal train123\n",
      "\tglobal labels123\n",
      "\tglobal train_unlabelled\n",
      "\tif run_type==\"dropout\":\n",
      "\t\tdrop_out_rate=[0,.2,.4,.5,.6,.8]\n",
      "\t\tnum_to_add=60000\n",
      "\t\tmax_iterations_if_0=3\n",
      "\t\tnum_to_add_each_iteration=[2000]\n",
      "\t\trepetitions=1\n",
      "\t\titerations=[3]\n",
      "\tif run_type==\"iterations\":\n",
      "\t\tdrop_out_rate=[0,.2,.4,.6,.8]\n",
      "\t\tnum_to_add=40000\n",
      "\t\tmax_iterations_if_0=3\n",
      "\t\tnum_to_add_each_iteration=[2000]\n",
      "\t\trepetitions=1\n",
      "\t\titerations=[.5,1,2,3,4,8]\n",
      "\telif run_type==\"cautiousness\":\n",
      "\t\tdrop_out_rate=[.5] \n",
      "\t\tnum_to_add=60000\n",
      "\t\tmax_iterations_if_0=10\n",
      "\t\tnum_to_add_each_iteration=[8000, 2000, 500, 125,0]\n",
      "\t\trepetitions=1\n",
      "\t\titerations=[5]\n",
      "\telif run_type==\"standard\":\n",
      "\t\tdrop_out_rate=[.5]\n",
      "\t\tnum_to_add=40000\n",
      "\t\tmax_iterations_if_0=3\n",
      "\t\tnum_to_add_each_iteration=[1000]\n",
      "\t\trepetitions=1\n",
      "\t\titerations=[3]\n",
      "\telif run_type==\"quick\":\n",
      "\t\tdrop_out_rate=[.5] \n",
      "\t\tnum_to_add=3000\n",
      "\t\tmax_iterations_if_0=3\n",
      "\t\tnum_to_add_each_iteration=[1000]\n",
      "\t\trepetitions=1\n",
      "\t\titerations=[.5]\n",
      "\t\ttrain123=train123[1:2000]#DEBUG\n",
      "\t\tlabels123=labels123[1:2000]\n",
      "\t\ttrain_unlabelled=train_unlabelled[1:10000]\n",
      "\n",
      "\n",
      "# perceptron_enssembles = [perceptron_enssemble.perceptron_enssemble(x) for x in num_perceptrons_in_enssemble]\n",
      "# for pe in perceptron_enssembles:\n",
      "import time\n",
      "def do_all_runs():\n",
      "\tfile_to_write_to=run_type+str(time.time())\n",
      "\twith open(file_to_write_to,'w') as f:\n",
      "\t\tf.write(\"Results:\\n\")\n",
      "\tfor i in xrange(repetitions):\n",
      "\t\tfor d in drop_out_rate:\n",
      "\t\t\tfor a in num_to_add_each_iteration:\n",
      "\t\t\t\tfor its in iterations:\n",
      "\t\t\t\t\tpe=ped.perceptron(d)\n",
      "\t\t\t\t\tcopy_of_labelled_features=[x for x in train123]\n",
      "\t\t\t\t\tcopy_of_labels=[x for x in labels123]\n",
      "\t\t\t\t\tcopy_of_unlabelled_features=[x for x in train_unlabelled]\n",
      "\t\t\t\t\tpe.train(train123,labels123,its)\n",
      "\t\t\t\t\tprint '\\n Semi-supervised learning with a perceptron.  Feature dropout rate:',d,'and adding', a, 'each iteration'\n",
      "\t\t\t\t\tnum_iterations=int(num_to_add/(a+1))+1\n",
      "\t\t\t\t\tif a==0:\n",
      "\t\t\t\t\t\tnum_iterations=max_iterations_if_0\n",
      "\t\t\t\t\ttest_errors, test_errors_averaged=\\\n",
      "\t\t\t\t\t\tdo_semi_supervised_learning(num_iterations,a, pe, \n",
      "\t\t\t\t\t\t\tcopy_of_labelled_features, copy_of_labels, \n",
      "\t\t\t\t\t\t\tcopy_of_unlabelled_features,its)\n",
      "\t\t\t\t\twith open(file_to_write_to,'a') as f:\n",
      "\t\t\t\t\t\tf.write(\"Not Averaged:\\tdropout:\"+str(d)+\"\\tadded_per_iteration\"+str(a)+\"\\titerations:\"+str(its))\n",
      "\t\t\t\t\t\tfor err in test_errors:\n",
      "\t\t\t\t\t\t\tf.write(\"\\t\"+str(err))\n",
      "\t\t\t\t\t\tf.write(\"\\n\\n\")\n",
      "\n",
      "\t\t\t\t\t\tf.write(\"Averaged:\\tdropout:\"+str(d)+\"\\tadded_per_iteration\"+str(a)+\"\\titerations:\"+str(its))\n",
      "\t\t\t\t\t\tf.write(\"na: \"+str(d)+\" \"+str(a))\n",
      "\t\t\t\t\t\tfor err in test_errors_averaged:\n",
      "\t\t\t\t\t\t\tf.write(\"\\t\"+str(err))\n",
      "\t\t\t\t\t\tf.write(\"\\n\")\n",
      "set_runtime_parameters(\"dropout\")\n",
      "do_all_runs()\n",
      "set_runtime_parameters(\"iterations\")\n",
      "do_all_runs()\n",
      "set_runtime_parameters(\"cautiousness\")\n",
      "do_all_runs()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# import cProfile\n",
      "# cProfile.runctx(\"do_all_runs()\",globals(),locals())\n",
      "\n",
      "# #perceptron.print_training_data(train123[0:n],labels123[0:n])\n",
      "# perceptrons.train(train123[0:n],labels123[0:n])\n",
      "\n",
      "# num_to_add_each_iteration=100\n",
      "# labels_and_confidence=perceptron.predict_labels_with_confidence(train_unlabelled)\n",
      "\n",
      "# def print_data():\n",
      "# \tprint \"\\nLABELLED DATA:\"\n",
      "# \tprint_labels_and_feats(labels123,train123)\n",
      "# \tprint \"\\nUNLABELLED DATA:\"\n",
      "# \tprint_labels_feats_and_confidence(labels_and_confidence,train_unlabelled)\n",
      "# #print_data()\n",
      "\n",
      "# n=len(labels_and_confidence)\n",
      "# assert(n==len(train_unlabelled))\n",
      "\n",
      "\n",
      "# '''Semi Supervised Learning'''\n",
      "# ilcf=[]\n",
      "# for i in xrange(n):\n",
      "# \tl,c=labels_and_confidence[i]\n",
      "# \tf=train_unlabelled[i]\n",
      "# \tilcf.append((i,l,c,f))\n",
      "# ilcf=sorted(ilcf, reverse=True,key=operator.itemgetter(2))\n",
      "# print \"\\nilcf\"\n",
      "# print ilcf #DEBUG\n",
      "# for i,l,c,f in ilcf[0:num_to_add_each_iteration]:\n",
      "# \tlabels123.append(l)\n",
      "# \ttrain123.append(f)\n",
      "# \t#print \"added: \", l, c, f\n",
      "# train_unlabelled = [f for i,l,c,f in ilcf[num_to_add_each_iteration:]]\n",
      "\n",
      "# print \"\\nLABELLED DATA - AFTER ADDING FROM UNLABELLED SET:\"\n",
      "# print_labels_and_feats(labels123,train123)\n",
      "\n",
      "# labels_and_confidence=perceptron.predict_labels_with_confidence(train_unlabelled)\n",
      "# print \"\\nUNLABELLED DATA:\"\n",
      "# print_labels_feats_and_confidence(labels_and_confidence,train_unlabelled)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "unindent does not match any outer indentation level (<ipython-input-18-e9ded5368f29>, line 127)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-e9ded5368f29>\"\u001b[1;36m, line \u001b[1;32m127\u001b[0m\n\u001b[1;33m    unlabelled_features=do_semi_supervised_iteration(num_to_add_each_iteration,\u001b[0m\n\u001b[1;37m                                                                               ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run run_log_linear_with_dropout.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "unindent does not match any outer indentation level (run_log_linear_with_dropout.py, line 114)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Willem\\SkyDrive\\Documents\\School\\SFU\\Research\\Dropout and Self-Training\\run_log_linear_with_dropout.py\"\u001b[1;36m, line \u001b[1;32m114\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m         \n^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}